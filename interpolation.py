import matplotlib.pyplot as plt
import math
import copy
from pathlib import Path
from random import random
import random
import numpy as np

import torch


from PIL import Image
from tqdm.auto import tqdm

from epsilon_star import *
from x_hat import *

from denoising_diffusion_pytorch import Unet, GaussianDiffusion, Trainer

from utils import *

# random seed has been fixed in denoising_diffusion_pytorch

# Getting device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}\t" +
      (f"{torch.cuda.get_device_name(0)}" if torch.cuda.is_available() else "CPU"))


# ****************************************
'''
interpolation between generated new images and nearest neighbor in training set
calculate the distance between the interpolation and x_hat
'''
def interpolation(
        real_x:torch.Tensor, 
        gen_x:torch.Tensor, 
        lam, 
        t,
        noise,
        model,
        args=args,
        show_pic=False
        ):  # 计算算出来的x与真实图像x0之间的插值,与相应的生成图像做插值
    intp = lam * gen_x + (1 - lam) * real_x
    x_input = q_sample(x_start = intp.clone(), t = t, noise = noise).to(torch.float32)  # forward process
    cal_x = weighted_x0(x_input, t, model, args=args)

    # calculate the L2 distance between interpolation and x_hat
    dist = (intp - cal_x).norm(p=2, dim=(1, 2, 3))
    dist_np = dist.cpu().numpy()
    '''
    # 显示图像
    if show_pic:
        intp_np = intp.cpu().detach().numpy()
        # intp_np = intp_np.reshape(b, c, w, h)
        fig, axs = plt.subplots(1, b, figsize=(10, 6))
        axs = axs.flatten()

        for i in range(b):
            axs[i].imshow(intp_np[i], cmap='gray')
            axs[i].axis('off')

        plt.tight_layout()
        plt.show()
    '''
    return dist_np  # numpy array: a batch of image be processed at the same time

def interpolate():
    # prepare parameters
    train_path = args.train_path  # the whole train set  e.g.  [num_trainset, c, h, w]
    real_path = args.real_path  # nearest neighbor in train set   e.g.  [num_gen, c, h, w]
    gen_path = args.gen_path  # generated by diffusion models   e.g.  [num_gen, c, h, w]
    real_x = np.load(real_path)
    gen_x = np.load(gen_path)
    b, c, h, w = gen_x.shape
    assert (b, c, h, w) == (args.batch_size, args.channels, args.image_size, args.image_size)
    assert real_x.shape == gen_x.shape

    # load diffusion model
    model, diffusion, trainer = load_model()

    # make sure [-1, 1] and to tensor
    real_x = normalize(real_x)
    gen_x = normalize(gen_x)
    real_x = torch.from_numpy(real_x).to(device)
    gen_x = torch.from_numpy(gen_x).to(device)

    # t
    time = args.time
    t = torch.full((b,), time, device=device).long()

    # noise
    noise = None
    noise = default(noise, lambda: torch.randn_like(gen_x))

    # go through all the lam and plot
    x_axis = [i * 0.01 for i in range(101)]
    dist = []
    for x_index in x_axis:
        dist.append(interpolation(real_x, gen_x, x_index, t, noise, model=model)[0])  # index can be changed within [0, b-1]

    plt.plot(x_axis, dist)
    plt.xlabel('lambda')
    plt.ylabel('l2 distance')
    plt.savefig('interpolation-distances.png')
    plt.show()

# *******************************************
'''
random direction, generated new images go along this direction and calculate the distance between the images and x_hat
'''
def go_along_direction(
        image:torch.Tensor, 
        direction:torch.Tensor, 
        lam,
        t,
        noise,
        model,
        args=args
        ):
    intp = lam * direction + image
    x_input = q_sample(x_start = intp.clone(), t = t, noise = noise).to(torch.float32)  # forward process
    cal_x = weighted_x0(x_input, t, model, args=args)

    # calculate the L2 distance between x_hat and images which go along some direction
    dist = (intp - cal_x).norm(p=2, dim=(1, 2, 3))
    dist_np = dist.cpu().numpy()
    return dist_np

def random_direction():
    # prepare parameters
    ckpt = 10
    mode = 'trained'

    train_path = ''  # the whole train set  e.g.  [num_trainset, c, h, w]
    gen_path = ''  # generated by diffusion models   e.g.  [num_gen, c, h, w]
    gen_x = np.load(gen_path)
    b, c, h, w = gen_x.shape

    # load diffusion model
    model, diffusion, trainer = load_model(ckpt=ckpt)

    assert (b, c, h, w) == (b, model.channels, diffusion.image_size, diffusion.image_size)

    # make sure [-1, 1] and to tensor
    gen_x = normalize(gen_x)
    gen_x = torch.from_numpy(gen_x).to(device)

    # t
    time = 10
    t = torch.full((b,), time, device=device).long()

    # noise
    noise = None
    noise = default(noise, lambda: torch.randn_like(gen_x))

    # random direction
    random_vector = torch.randn(c * h * w)
    direction = random_vector / random_vector.norm()
    direction = direction.reshape(1, c, h, w).repeat(b, 1, 1, 1).to(device)

    # go through all the lam and plot
    x_axis = [i * 0.01 for i in range(101)]
    dist = []
    for x_index in x_axis:
        dist.append(go_along_direction(gen_x, direction, x_index, t, noise, model=model, train_path=train_path, mode=mode)[0])  # index can be changed within [0, b-1]

    plt.plot(x_axis, dist)
    plt.xlabel('lambda')
    plt.ylabel('l2 distance')
    plt.savefig('rand direction.png')
    plt.show()


if __name__ == '__main__':
    interpolate()